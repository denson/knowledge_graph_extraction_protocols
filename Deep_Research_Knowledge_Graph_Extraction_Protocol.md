# Deep Research Knowledge Graph Extraction Protocol (Enriched Version)

[Knowledge Crystal](https://knowledgecrystal.com/) is a platform dedicated to organizing and presenting structured knowledge in a clear, accessible format. It focuses on building knowledge graphs and crystals to help users efficiently navigate complex information.


## Overview

This protocol outlines a structured approach for extracting a **Knowledge Graph (KG)** from research papers, now enhanced with optional semantic enrichment capabilities. It is organized into core extraction steps and enrichment steps, with clear points for human feedback. The **core extraction phase** covers identification of fundamental components (sections, concepts, methods, etc.) and outputs a baseline KG. An **optional enrichment phase** can then add richer semantic relationships (e.g., which methods are used, what tasks are supported) to the KG. A **human QA (Quality Assurance)** step is integrated between these phases to verify and refine the output, ensuring accuracy before and after enrichment. The sections below describe each part of the protocol in detail, specifying which aspects are core extraction versus enrichment and where human review is applied.

## System Prompt & Core Extraction Guidelines

In the core extraction phase, the Large Language Model (LLM) is instructed (via the system prompt) to read a research paper and produce a structured knowledge graph representation in **JSON-LD** format. The system prompt should clearly define the extraction tasks and expected output structure. The following elements are **core** to the extraction and should be included in the LLM instructions:

* **Document Metadata:** Extract basic information such as the paper title, authors, year, and publication venue. Include these as top-level attributes in the JSON-LD (e.g., as a `Paper` node with properties like `dc:title`, `dc:creator`, etc.).
* **Section Highlights:** Identify the main sections of the paper (Introduction, Methods, Results, Conclusion, etc.) and provide a brief summary or the key point of each section. These can be represented as nodes or as structured entries under a `sections` list, each with a section title and summary.
* **Key Concepts and Tasks:** Extract important domain-specific concepts, problems, or tasks that the paper addresses. For example, identify terms for scientific concepts, research questions, or application areas mentioned. These should be listed as **Concept** nodes in the KG (e.g., `kg:Concept` entries).
* **Methods and Techniques:** Extract the names of methods, models, algorithms, or techniques introduced or used in the paper. These are listed as **Method** nodes (e.g., `kg:Method` entries). Each method node may include attributes like whether it’s a new proposal or an existing approach referenced.
* **Core Relationships:** Capture basic factual relationships using standard predicates. For example, link authors to the paper (`dc:creator`), link concepts or methods to the paper or to specific sections (e.g., `kg:mentionedIn` or `schema:isPartOf` for a concept appearing in a section). These core relations ensure the graph is structured (paper has sections, sections contain concepts/methods).
* ***(New – Enriched Predicate Suggestions):*** *Optionally, have the LLM propose additional **semantic relationships** between the extracted concepts and methods.* Based on the content of the paper, the LLM can identify potential relationships such as a method **using** a certain approach, a model **extending** a prior model, a technique **supporting** a specific task, or combining aspects of multiple concepts. These should be clearly marked as **candidate** relationships – for example, the LLM could list them under a “candidateRelations” section or annotate them as tentative. The system prompt should emphasize that these enriched predicates (e.g., `kg:usesMethod`, `kg:supportsTask`, `kg:extends`, `kg:combines`) are **suggestions** only. They are not to be treated as confirmed facts without validation. By allowing the LLM to output such candidates (with an indication like `"confidence": "low"` or simply a note that they require review), the protocol captures possible deeper insights from the paper for human reviewers to evaluate.

**Output Format:** The LLM’s output should be a JSON-LD structured graph containing the above elements. Each entity (paper, sections, concepts, methods) should be a node with a type and relevant properties. The core extraction relationships (like section hierarchy or mentions) should be included as edges in the JSON-LD. Any **candidate enriched relationships** suggested by the LLM should either be listed separately or clearly flagged in the JSON-LD (e.g., as a separate graph or with a boolean flag) so that they can be distinguished during review. The system prompt can provide an example JSON-LD structure to guide the LLM, ensuring consistency. It should also reiterate that all content must be drawn from the paper and that **no external hallucinated information is allowed**.

## Quality Assurance (Human Review & Refinement)

After the LLM produces the initial knowledge graph, a human reviewer (or QA engineer) examines the output. This **QA phase** is critical for refining the KG and integrating the LLM’s suggestions appropriately. Key steps in the QA review include:

1. **Validate Core Content Extraction:** Verify that all fundamental information from the paper is captured and correctly represented. Check that the title, authors, and other metadata are correct, all major sections are included, and key concepts/methods mentioned in the paper are present as nodes. If anything important is missing or misinterpreted, manually correct or augment the KG.

2. **Check Structure and Formatting:** Ensure the JSON-LD is well-formed and adheres to the expected schema. All nodes should have appropriate types (`kg:Paper`, `kg:Section`, `kg:Concept`, `kg:Method`, etc.), and relations should use consistent predicates (e.g., using the same predicate for similar relations across entries). Correct any structural issues or inconsistencies.

3. **Disambiguate and Normalize Entities:** Review the extracted concepts and methods for clarity and uniqueness. If the LLM output includes synonyms or variations referring to the same concept (e.g., "CNN" vs "Convolutional Neural Network"), choose one standard representation and unify the nodes or labels. Similarly, ensure that each method or concept node is distinct and clearly labeled, possibly adding brief descriptions if needed for clarity.

4. **Review LLM-Suggested Enriched Predicates:** For each **candidate relationship** proposed by the LLM (from the enriched predicates suggestions in the system prompt output), do a careful evaluation:

   * **Accept or Refine:** If a suggested relationship is clearly supported by the paper’s content (e.g., the paper explicitly says “Our model uses a fuzzy logic controller”), accept it. You may rename the predicate to a preferred wording if needed (for instance, the LLM might output `kg:usesMethod`, but you decide `kg:utilizes` is the standardized predicate name in your schema). Update the JSON-LD: confirm the triple and ensure the predicate is used consistently.
   * **Rename or Generalize:** If the idea is correct but the phrasing or level of specificity is not ideal, adjust the predicate or objects. For example, if the LLM suggested `kg:extends` but the relation is more of a minor modification rather than a true extension, you might use a predicate like `kg:modifies` or a more general `kg:relatedTo`. Align the naming with domain-specific ontology or schema standards if available (possibly mapping to existing ontology terms).
   * **Reject if Unfounded:** If a suggested relation is not clearly supported by the paper or seems to be a hallucination or overreach, do not include it. For instance, if the LLM guessed "Technique A combines Method B and C" but the paper doesn’t explicitly make that claim, it should be omitted. Remove or mark these relations as rejected in the review notes.
   * **Add Missing Relationships:** The human reviewer can also introduce additional semantic relationships that were obvious in the paper but the LLM didn’t suggest. For example, if the paper states a specific **goal or application** of a method (“Method X is used for task Y”), ensure this is captured (e.g., add `kg:supportsTask` or similar with the appropriate nodes). Likewise, if domain-specific predicates are relevant (like `kg:evaluatedWith` for an evaluation metric or `kg:comparesTo` for comparative baselines), the reviewer can manually add those with the proper subject and object from the KG.

5. **Finalize the Core KG:** After verification and edits, the output should be a clean, accurate JSON-LD knowledge graph representing the paper. The core extraction information is now confirmed, and any enriched relationships that were accepted are integrated. Ensure all new or adjusted predicates (from the previous step) are documented or noted for consistency (for example, maintain a list of all predicates used and their meanings). The KG at this stage is considered the **validated core graph with optional enrichment** included as decided by the reviewer.

Throughout the QA phase, the human is effectively **in the loop**, correcting any errors from the LLM and judiciously incorporating enrichment suggestions. This feedback loop guarantees that the knowledge graph is both faithful to the source material and enriched only with relationships that make sense.

## Optional Enrichment Pass (Post-KG)

*This phase is an advanced, optional step to further enhance the knowledge graph with rich semantic relationships. It is typically performed after the core KG has been validated, and is most useful when the end application requires deep reasoning, explainable AI paths, or enhanced search capabilities.*

In the enrichment pass, a secondary process (which could be another LLM prompt or a specialized pattern-mining tool) analyzes the paper and the newly constructed KG to infer additional **subject–predicate–object** triples among the **Concept** and **Method** nodes (and occasionally other nodes like tasks or datasets). The goal here is to go beyond the explicit extractions and surface implicit or hidden relationships that can enrich the semantic network. Key aspects of this enrichment process include:

* **Automated Relationship Mining:** The tool (or second LLM) scans the paper’s text and the context of the extracted nodes to identify potential relationships. It looks for language patterns or factual statements such as *“X uses Y”*, *“X is based on Y”*, *“X improves upon Y”*, *“X is a type of Z”*, or *“X was applied to solve Y”*. These correspond to semantic predicates like `kg:usesMethod`, `kg:extends`, `kg:builtOn`, `kg:supportsTask`, `kg:instanceOf`, etc. The enrichment tool can be guided by a prompt or rules to output any detected relationship in a structured form (for example, as a list of triples or sentences).
* **Structured Semantic Assertions:** For each identified relationship, the enrichment pass produces a clear assertion. For example:

  * *Assertion:* “**Model X** uses **fuzzy logic**.” → *Enriched triple:* `("Model X", "kg:usesMethod", "Fuzzy Logic")`
  * *Assertion:* “**Framework Y** supports **task Z**.” → *Enriched triple:* `("Framework Y", "kg:supportsTask", "Task Z")`
  * *Assertion:* “**Algorithm A** combines **Technique B** and **Technique C**.” → *Enriched triple:* `("Algorithm A", "kg:combines", ["Technique B", "Technique C"])` (this one might result in two separate relations or a compound object).
    Each assertion is essentially a new edge in the knowledge graph, connecting two existing nodes (or a node to a new concept node if that concept wasn’t explicitly extracted before).
* **Conversion to JSON-LD:** The suggested relationships from this pass are then converted into the JSON-LD format, consistent with the core KG structure. This means adding new predicate entries in the graph that link the subject and object nodes. For instance, if `Model X` and `Fuzzy Logic` are already nodes in the KG, we would add `"kg:usesMethod": "Fuzzy Logic"` under the `Model X` node (or a separate triple structure linking them, depending on the JSON-LD representation). All new predicates should be used with a proper prefix (e.g., `kg:`) and, if applicable, defined in the context. It’s recommended to keep these predicate names consistent and intuitive (e.g., always use `kg:usesMethod` for any "uses" relationship). Optionally, include **type declarations** or documentation for these new predicates – for example, noting that `kg:usesMethod` is a sub-property of a more general relationship or indicating its domain and range (this can be done in an ontology file or context section, outside the immediate JSON-LD of the paper’s data if needed).
* **Schema and Consistency:** All enriched predicates should align with a consistent schema. If an internal ontology or vocabulary is in use, incorporate the new predicates into that schema (ensuring there are no duplicates or naming conflicts). For example, if using a prefix `kg:` for custom relations, maintain a list of these (like `kg:usesMethod`, `kg:supportsTask`, `kg:extends`, `kg:combines`, etc.) with clear meanings. This helps future users or AI agents interpret the KG correctly.
* **Optional Human Vetting:** Although this enrichment pass is often automated, it can be looped back to human review as well. Especially if a second LLM is used, a quick validation of its newly suggested triples is prudent. Human experts can confirm that these inferred relations indeed make sense and are supported by the paper. This is similar to the earlier QA step but focused on the enrichment output. Any incorrect or speculative triples should be removed or flagged.

After this enrichment pass, the knowledge graph will contain both the **core extracted knowledge** (from the initial LLM pass) and **additional semantic links** that provide deeper insight into how the paper’s concepts and methods relate to each other. This enriched KG is particularly useful for downstream applications like semantic search (where a query might traverse the “usesMethod” links) or for powering LLM-based agents that can explain relationships (since the graph now encodes paths like “This method was used to accomplish that task”). It’s important to note that this phase is **optional** – if the use case only requires the basic extracted info (e.g., for a simple summary or indexing), one might skip the enrichment. However, when **explainability, reasoning, or complex query answering** is needed, applying this enrichment step ensures the knowledge graph captures not just the entities from the paper, but also the nuanced relationships between those entities.

## Summary of Core vs. Enrichment Steps

To clarify the division of labor: the **core extraction** (System Prompt phase) yields the primary nodes and basic relationships of the paper’s content – this is always done and forms the foundation of the KG. The **enrichment** steps (LLM-suggested predicates and the optional post-KG pass) contribute additional edges that connect those core nodes with semantic meaning; these are secondary and should be treated with caution until verified. Human feedback is woven into the process during the **QA phase**, where the core output is validated and the enrichment suggestions are curated. By following this protocol, one ensures a high-quality knowledge graph that is faithful to the source material and enhanced with valuable semantic context when needed, all while maintaining a clear distinction between verified facts and candidate inferences.
