# Self-Organizing Graph Reasoning Evolves into a Critical State for **Continuous Discovery Through Structural–Semantic Dynamics**

Markus J. Buehler<sup>1</sup>

Massachusetts Institute of Technology, 77 Mass. Ave, Cambridge, MA 01921, USA.

(\*Electronic mail: mbuehler@MIT.EDU.)

(Dated: 25 March 2025)

We report fundamental insights into how agentic graph reasoning systems spontaneously evolve toward a critical state that sustains continuous semantic discovery. By rigorously analyzing structural (Von Neumann graph entropy) and semantic (embedding) entropy, we identify a subtle yet robust regime in which semantic entropy persistently dominates over structural entropy. This interplay is quantified by a dimensionless Critical Discovery Parameter  $(\mathscr{D})$ , which stabilizes at a small negative value ( $\mathcal{D} \approx -0.03$ ), indicating a consistent excess of semantic entropy. Empirically, we observe a stable fraction ( $\sim$  12%) of "surprising" edges—links between semantically distant concepts—providing evidence of long-range or cross-domain connections that drive continuous innovation. Concomitantly, the system exhibits scale-free and small-world topological features, alongside a negative cross-correlation between structural and semantic measures, reinforcing the analogy to self-organized criticality. These results establish clear parallels with critical phenomena in physical, biological, and cognitive complex systems, revealing an entropy-based principle governing adaptability and continuous innovation. Crucially, semantic richness emerges as the underlying driver of sustained exploration, despite not being explicitly used by the reasoning process. Our findings provide interdisciplinary insights and practical strategies for engineering intelligent systems with intrinsic capacities for long-term discovery and adaptation, and offer insights into how model training strategies can be developed that reinforce critical discovery.

## I. INTRODUCTION

Generative modeling for language, vision and other modalities has received significant interest in the past  $\overline{\text{years}}^{1-3,11,20,23,26,30}$ , including the development of reasoning models that exhaust thinking and reflection strategies before responding to tasks<sup>4,13,33</sup>. However, little is known about the mechanisms by which models, especially reasoning models, develop answers and whether general principles can be extracted.

One particular class of reasoning models, agentic deep graph reasoning models such as Graph-PRefLexOR, iteratively construct knowledge graphs by recursively applying neural reasoning over extended test-time compute  $12,13,16,32$ . While previous work has established the overall capability of such graph-native reasoning models, the fundamental physical principles governing their structural and semantic evolution remain largely unexplored, albeit earlier work has proposed graph-focused strategies that also incorporate category theory<sup>13-15,18,19,28</sup>. The structured generation of thinking mechanisms offers the potential to conduct more rigorous analyses of the resulting graph structures. Relatedly, research indicates that standard Transformer architectures can be interpreted as a variant of the Graph Isomorphism Network (GIN), where attention mechanisms function over relational structures rather than purely sequential token representations<sup>15</sup>. These relations of AI models with established concepts from mathematics and physics provide grounds for a wider-ranging analysis of their behavior through a lens of dynamical systems.

The work reported here uses the series of graph networks obtained in earlier work, specifically<sup>14</sup> (see, Materials and Methods for details, and particularly the original paper, where the algorithm summarized in Figure 1 is explained in further detail). As shown in the figure, the graphs were obtained through an iterative, agentic process where a reasoning-native large language model autonomously expanded and refined a knowledge graph. At each step, the system generated new concepts and relationships, integrated them into the graph, and formulated subsequent prompts based on the evolving structure. This resulted in hundreds of graphs that allow us to study their detailed evolution as the reasoning process expands. The earlier work<sup>14</sup> has shown notable properties of these graphs, such as that it resulted in a scale-free network with emergent hubs and bridges linking disparate knowledge clusters $8.29$ . Over hundreds of iterations, new nodes and edges continuously appeared, centrality measures evolved, and shortest path distributions adapted, leading to increasingly distributed connectivity.

Fig. 2 shows a depiction of the network generated at the end of the reasoning iterations $13-15$ . Complementing the twodimensional projection in Fig. 2, Fig. 3 shows the growth of the network over reasoning iterations in a three-dimensional view. We note that a wealth of analysis is included in the earlier work $14,15$ , on top of which this study is built. We refer readers to the original papers for further details, albeit key results will be reviewed here for clarity.

In this paper, we present insights revealing how agentic graph reasoning systems spontaneously evolve behaviors analogous to critical phenomena observed in physical, biological, and cognitive complex systems<sup>21,29</sup>. Through rigorous quantitative analysis of structural entropy (Von Neumann graph entropy) and semantic embedding entropy we posit that a graph representing an evolving knowledge system has two parallel dimensions: network topology and conceptual diversity. Hence, complementing Von Neumann graph entropy, we define semantic entropy as a measure quantifying how conceptually diverse or spread out the node representations are within a learned embedding space, computed

Image /page/1/Figure/0 description: The image shows a flowchart describing an iterative reasoning process. The process starts with a "Define Initial Question" box. Then, inside a dashed box labeled "Iterative Reasoning i < N", the process continues with "Generate Graph-native Reasoning Tokens", followed by "Parse Graph (Extract Nodes and Relations)". The extracted graph is then merged with a larger graph by "Merge Extracted Graph with Larger Graph (Append Newly Added Nodes/Edges)". A "Generate New Question Based on Last Extracted Added Nodes/Edges" box feeds back into the "Generate Graph-native Reasoning Tokens" box, completing the iterative loop. Finally, the process ends with a "Final Integrated Graph" box.

FIG. 1. Algorithm used for iterative knowledge extraction and graph refinement as reported in  $14$ . At each iteration i, the model generates reasoning tokens that include a graph representation of the thinking process (blue). A local graph  $\mathcal{G}_{local}^{i}$  is then extracted (violet) and merged with the global graph  $\mathscr G$  (light violet). A follow-up task is then generated based on the latest extracted nodes and edges in  $\mathcal{G}^i_{local}$ (green), leading to iterative reasoning (orange), so that the model expands the graph with increasing number of nodes and edges.

via the spectral properties of a similarity (cosine-based) adjacency matrix derived from pretrained language model embeddings. These measures of entropy serve as analogues to physical entropy measures. This concept builds on earlier work<sup>17</sup> that introduced an early, formal approach to semantic information rooted in logical probability and content, establishing a foundation for later entropy-based interpretations of meaning. Other research<sup>24</sup> introduced word embedding techniques that underpin contemporary distributional semantics, providing the vector-space basis for the concept of semantic adiacency construction. Related, information-theoretic tools<sup> $27$ </sup> were applied to complex networks, illustrating how entropy concepts elucidate architectural constraints and evolutionary dynamics, a perspective we extend by incorporating semantic embeddings.

## **RESULTS AND DISCUSSION** .

Our analysis is conducted over the growing graphs that emerge during a lengthy reasoning process. Fig. 4(a) shows that both structural (Von Neumann graph entropy) and semantic entropy rapidly increase and stabilize over the course of iterative reasoning cycles, clearly indicating continuous growth in both structural and semantic complexity. However,

Fig. 4(b) reveals that semantic entropy consistently remains higher than structural entropy throughout all iterations, explicitly signifying sustained semantic dominance in the network's evolution. Taken together, the data shows that the system selforganizes to maximize informational entropy in its knowledge network.

To more deeply understand this interplay, we computed the cross-correlation between these entropies (Fig.  $4(c)$ ), explicitly demonstrating a clear critical transition near iteration 400, where structural-semantic correlation shifts from positive (initially co-evolving structure and semantics) to strongly negative values. This negative correlation explicitly indicates that structural decisions increasingly diverge from underlying semantic relationships, systematically exploring structurally justified yet semantically novel connections.

Finally, Fig. 5(a) shows a two-dimensional PCA projection of semantic embeddings, with nodes colored by their Louvain structural community memberships. Notably, structural communities are not distinctly separated in semantic embedding space; instead, they appear intermingled and partially overlapping. This partial decoupling between structural clusters and semantic similarity demonstrates that the knowledge graphs produced by the reasoning model encode structural and semantic information through fundamentally distinct but complementary dimensions. Such a result reveals how the coexistence and partial independence of semantic and structural information allow the system to remain simultaneously robust (via structural organization) and flexible (via semantic novelty). This is because the Louvain algorithm discovers communities based purely on the graph's adjacency. Meanwhile, semantic embeddings represent conceptual similarity. Because we see multiple structural communities overlapping or interspersed in embedding space, the plot directly visualizes the partial semantic-structural divergence that our earlier metrics indicated. Fig. 5(b) shows a distance histogram, whose skewed distribution confirms that while structural communities have some semantic coherence, they also contain outlier or bridging nodes.

Taken together, these results reveal important connections between physical concepts of entropy, critical phase transitions, and continuous discovery processes in artificial intelligence reasoning processes. They establish clear parallels between emergent graph reasoning and physical systems, suggesting novel interdisciplinary approaches to engineer intelligent, adaptive reasoning systems informed by principles from statistical physics and complex system theory, whereby the graph reasoning process spontaneously evolves toward a "critical state" that sustains ongoing discovery.

### A. Unified Concepts of Critical Discovery

Based on our observations, we propose a unified theory, the critical discovery principle, which succinctly captures the inherent dynamics of agentic reasoning systems by quantifying the relative dominance of structural entropy compared to semantic entropy. The central premise is that autonomous reasoning processes spontaneously evolve toward and sustain a

Image /page/2/Figure/0 description: The image shows a complex network graph with numerous nodes and edges. The nodes are represented by small, colored circles, and the edges are represented by thin, curved lines connecting the nodes. The colors of the nodes vary, including shades of blue, green, pink, orange, and brown. The edges are also colored, but they appear more muted and blend together, creating a dense web of connections. The overall structure of the graph is somewhat amorphous, with clusters of nodes and edges concentrated in certain areas. The background is plain white, which helps to emphasize the network graph. The graph appears to be a visual representation of a complex system or network, possibly depicting relationships between different entities or concepts.

FIG. 2. The complete knowledge graph generated by the agentic deep graph reasoning model (Graph-PRefLexOR<sup>15</sup>) after iterative evolution. Nodes and edges emerge iteratively through recursive reasoning, forming complex structural communities. Colors reflect different communities (up to 20 unique communities shown).

critical balance between structural complexity and semantic novelty. This balance, where the system maintains itself near criticality without external tuning, is quantified by a dimensionless discovery parameter defined as:

$$
\mathscr{D} = \frac{S_{struct} - S_{sem}}{S_{struct} + S_{sem}},
$$

where  $S<sub>struct</sub>$  and  $S<sub>sem</sub>$  denote structural and semantic entropies, respectively.

In our numerical analysis of the results, the Critical Discovery Parameter  $(\mathscr{D})$  explicitly quantifies this balance between structural and semantic entropy (Fig. 4(d)). The parameter stabilizes near a small negative value ( $\mathscr{D} \approx -0.03$ ), explicitly confirming that semantic entropy subtly dominates structural entropy, mirroring the competition between energy

 $\overline{\mathcal{A}}$ 

Image /page/3/Figure/1 description: The image shows the growth of a network over reasoning iterations. The network starts with a few nodes and edges, and as the iterations increase, the network becomes more complex and dense. The nodes are represented by circles, and the edges are represented by lines. The color of the nodes and edges may vary. The network appears to be growing in a non-uniform manner, with some areas becoming more dense than others.

FIG. 3. Growth of the network over reasoning iterations, threedimensional view. The evolution of the network over reasoning iterations is clearly visible.

Image /page/3/Figure/3 description: The image contains four plots, labeled (a), (b), (c), and (d). Plot (a) shows "Von Neumann Graph Entropy (Structural)" as a function of "Iteration". The entropy increases from approximately 3 to 8 as the iteration increases from 0 to 1000. Plot (b) shows "Semantic Graph Entropy" as a function of "Iteration". The entropy increases from approximately 3 to 8 as the iteration increases from 0 to 1000. Plot (c) shows "Cross-correlation" as a function of "Iteration". The cross-correlation decreases from 10^0 to -10^0 as the iteration increases from 0 to 1000. Plot (d) shows "Critical Discovery Parameter (D)" as a function of "Iteration". The discovery parameter fluctuates between -0.065 and -0.030 for the first 200 iterations, then gradually increases to approximately -0.030 as the iteration increases from 200 to 1000.

FIG. 4. Evolution and comparative analysis of structural and semantic entropy during graph reasoning. (a) Structural entropy, quantified by Von Neumann Graph Entropy, increases rapidly initially and stabilizes gradually, indicating consistent structural complexity growth. (b) Semantic entropy evolves similarly but remains consistently higher than structural entropy, indicating sustained semantic complexity dominance. (c) Cross-correlation between structural and semantic entropy reveals a critical transition near iteration 400, shifting from positively correlated (co-evolution) to negatively correlated dynamics (semantic-structural divergence), reminiscent of a phase transition.(d) The Critical Discovery Parameter  $(\mathscr{D})$  stabilizes at a slightly negative value ( $\mathcal{D} \approx -0.03$ ), explicitly confirming persistent semantic entropy dominance and guiding structural evolution towards sustained exploratory innovation. Together, these results explicitly demonstrate that semantic dynamics consistently lead and shape structural evolution, underpinning continuous semantic exploration and innovation.

Image /page/4/Figure/0 description: The image contains two subplots, labeled (a) and (b). Subplot (a) is a scatter plot showing PCA Component 1 on the x-axis and PCA Component 2 on the y-axis. The data points are colored according to a color bar labeled "Community ID", ranging from 0 to 35. Subplot (b) is a histogram showing "Distance from Community Centroid (PCA space)" on the x-axis and "Number of Nodes" on the y-axis. The histogram bars are colored according to their x-axis value, with the color transitioning from blue to red as the distance increases. The y-axis ranges from 0 to 350. The x-axis ranges from 0 to 5. The title of the figure is "Semantic Embedding Space and Structural Communi".

 $FIG<sub>5</sub>$ Semantic Embedding Space and Structural Community Decoupling. (a) Two-dimensional PCA projection of semantic node embeddings, colored according to structural communities identified via the Louvain method. The observed partial mixing of community colors in semantic space demonstrates a critical decoupling between semantic embeddings and structural clusters, highlighting complementary yet distinct forms of knowledge encoded within the evolving graph. It confirms that the system's structural connections are not dictated simply by semantic proximity. (b) Histogram of node distances from their respective community centroids in PCA space. The *x*-axis represents the distance from the centroid, while the *y*-axis denotes the number of nodes at each distance. The color gradient reflects node density, with red indicating higher counts and blue representing lower values. The distribution is right-skewed and longtailed, with most nodes clustered around a distance of 1, while a few nodes exhibit significantly larger distances.

and entropy in phase transitions. This is reminiscent of a second-order phase transition: initially, structure and content co-evolve (like an order parameter following the external field), but beyond the critical point, their relationship inverts - similar to how beyond the Curie temperature, magnetization collapses even as thermal fluctuations (entropy) continue to increase.

To empirically validate this theory, we explicitly analyze the evolution of surprising edges—edges that are structurally

connected but semantically distant-in Fig. 6(a). Although the total edge count continuously increases, the ratio of surprising edges

$$
\frac{N_s}{N}\rightarrow \alpha,
$$

stabilizes around  $\alpha \approx 12\%$  (Fig. 6(b)). This explicitly indicates a sustained intrinsic mechanism for semantic exploration and innovation. This stable fraction explicitly characterizes a subtle balance: semantic entropy consistently guides structural evolution toward novel relationships without allowing the system to descend into disorder or rigidity. Such behavior closely mirrors critical phenomena observed in physical and biological systems, which similarly exhibit a delicate equilibrium between predictable structural order and adaptive semantic novelty. The persistent fraction  $\alpha$  thus explicitly emerges as an empirical hallmark of criticality, analogous to residual disorder found at critical points in physical systems. Interestingly, the fraction of cross-domain connections aligns with magnitudes seen in small-world networks needed to drastically reduce path lengths<sup>22,31</sup>. This hints that the reasoning process naturally populates the graph with just enough longrange links to hit a connectivity threshold, ensuring information can propagate across the entire network efficiently. This nuanced yet robust semantic dominance explicitly validates the Critical Discovery Principle, highlighting semantic complexity as the primary driver behind continuous exploratory innovation.

To further elucidate the structural-semantic dynamics, we computed the correlation between betweenness centrality  $(BC)$  and local semantic neighbor diversity (Fig.  $6(c)$ ). In the early iterations, the correlation fluctuates significantly as the network is small or changing quickly, with early high positive correlation indicating an aggressive initial phase of semantic bridging. As the graph grows the correlation settles at a positive level, saturating at around 400 iterations. This suggests that high-BC nodes, which act as bridges, tend to have neighbors that are more spread out in embedding space. The network consistently maintains moderate semantic diversity around central nodes, providing structural stability and continuous innovation through balanced semantic exploration.

In summary, our theory captures the subtle yet persistent semantic dominance and sustained exploratory capability observed experimentally. The stable fraction of structurally coherent yet semantically distant ("surprising") edges explicitly serves as empirical validation of the Critical Discovery Principle, highlighting both its predictive power and potentially a broad conceptual relevance across artificial intelligence, physics, and complexity science.

## **B.** Interdisciplinary Parallels and Universality

The Critical Discovery Principle identified in our agentic graph reasoning model closely mirrors phenomena observed across diverse natural and artificial complex systems. In biological networks, gene regulatory and protein interaction networks maintain stability through structurally coherent inter-

Image /page/5/Figure/0 description: The image contains three subplots, labeled (a), (b), and (c), each displaying a graph with 'Iteration' on the x-axis, ranging from 0 to 1000. Subplot (a) shows 'Edge Count' on the y-axis, with two lines representing 'Total Edges' (blue) and 'Surprising Edges' (red). The 'Total Edges' line increases linearly from 0 to approximately 12000, while the 'Surprising Edges' line increases from 0 to around 1500. Subplot (b) shows 'Ratio (Surprising / Total)' on the y-axis, with a green line fluctuating between 0.06 and 0.18. The line starts at approximately 0.06, peaks at 0.18, and then stabilizes around 0.12 after 600 iterations. Subplot (c) shows 'Correlation Coefficient' on the y-axis, with a blue line representing 'Betweenness centrality vs Local Neighbor Diversity'. The line starts at approximately 0.7, rapidly decreases to 0.2 within the first 200 iterations, and then gradually decreases to 0.15 by the end of the 1000 iterations. The title of the figure is 'FIG 6 Analysis of surprising edges as a measure of continuous d'.

FIG. 6. Analysis of surprising edges as a measure of continuous discovery. (a) Evolution of total and surprising edge counts; (b) The stable fraction ( $\sim$  12%) of surprising edges indicates sustained semantic exploration and discovery capacity. (c) Correlation between betweenness centrality and local semantic neighbor diversity. After large values in small and early-stage graphs (aggressive initial phase of semantic bridging), the correlation stabilizes at a positive value, indicating that nodes on many shortest paths connect neighbors with more diverse semantic embeddings.

actions explicitly guided by underlying functional (semantic) requirements, continuously introducing exploratory variations essential for evolutionary adaptation. Similarly, neural and cognitive systems exhibit structural-functional coupling near critical states (e.g., neuronal avalanches), promoting cognitive flexibility and innovation through persistent semantic enrichment. Ecological systems analogously balance stable structural interactions among species with exploratory semantic 6

In social and economic contexts, innovation networks naturally balance structural coherence—stable technological or economic sectors—with continuous semantic-driven exploration of novel, disruptive ideas essential for sustained growth. Physical and material systems undergoing second-order phase transitions (e.g., magnetic, superconducting, or critical fluid systems) also display analogous behaviors, characterized by subtle structural-semantic interplay at critical boundaries. Similarly, glassy and amorphous materials maintain residual structural defects at criticality, explicitly providing mechanical adaptability reminiscent of our model's structurally coherent yet semantically novel ("surprising") edges. Finally, artificial intelligence systems, particularly reinforcement learning frameworks, inherently balance exploitation of structurally known knowledge with exploration driven by semantically novel opportunities, embodying the universal criticality we explicitly describe.

These interdisciplinary parallels explicitly suggest that the subtle yet persistent semantic dominance and critical discovery dynamics observed in agentic reasoning systems are not isolated phenomena, but rather manifestations of a deep, universal organizing principle governing adaptability, innovation, and discovery across complex adaptive systems. Recognizing such universality explicitly provides foundational insights for interdisciplinary theory and practical strategies to engineer robust, semantically-driven, innovative, and adaptive intelligent systems.

# C. Prediction: Emergent Behavior in Novel Reasoning **Scenarios**

Drawing inspiration from hierarchical organization observed in biological and physical complex systems operating near criticality, we predict that when the reasoning model encounters significantly larger-scale or multi-layered conceptual problems—tasks fundamentally differing in complexity or dimensionality from previously encountered scenarios—it will spontaneously generate hierarchical structures and multi-scale conceptual organization.

Specifically, analogous to biological networks (e.g., neural circuits, ecosystems) and physical systems exhibiting scaleinvariant phenomena near critical points, we anticipate that the reasoning graph will dynamically reorganize into nested communities characterized by clear hierarchies and scale-free connectivity distributions. Structural entropy would initially increase, reflecting new complexity from encountering novel conceptual scales, followed by the spontaneous formation of multi-scale modular structures driven purely by algorithmic structural evolution. Semantic entropy-measured independently—will likely exhibit multiple plateaus, corresponding to semantic stabilization at distinct hierarchical scales of abstraction. We further anticipate that the stable fraction of structurally justified yet semantically distant ("surprising") edges will progressively decrease at finer, local scales, while remaining elevated at global scales, thus ensuring continuous discovery and innovation at higher levels of abstraction.

This prediction reflects known universal properties of critical systems, where introducing entirely new spatial, temporal, or organizational scales spontaneously triggers hierarchical and scale-free pattern formation. Empirically confirming this emergent behavior in future Graph-PRefLexOR experiments would represent compelling evidence of a deeper universal principle underlying complex reasoning and intelligence across diverse scales. As shown in earlier work<sup>14</sup> our system exhibits scale-free degree distributions, smallworld connectivity, and a stable fraction of semantically distant edges—consistent with classic self-organized criticality signatures. Together with the near-balanced but persistent dominance of semantic entropy, these findings align with core self-organized criticality principles: the network's structure and semantic content spontaneously organize toward a critical point, sustaining continuous novelty while avoiding trivial ordering or random disintegration. In fact, it aligns with the notion of self-organized criticality, where we see a sustained capacity for novelty (semantic) that does not collapse into either random chaos or purely local uniformity. A deeper demonstration of this concept would require further analysis to dig deeper into scale invariance and power-law behaviors.

## D. Future work: Maximizing Discovery via **Reinforcement Learning**

Inspired by the critical discovery dynamics identified in this study, we propose a practical reinforcement learning (RL) framework to explicitly maximize the capacity for continuous semantic discovery in agentic graph reasoning systems. Our empirical results suggest that the graph spontaneously stabilizes near a slightly negative critical discovery parameter ( $D \approx -0.03$ ), indicative of a subtle but persistent semantic dominance. However, this empirically observed state might not necessarily represent the global optimum. Thus, we introduce a flexible reinforcement learning approach that can systematically guide the system toward optimal conditions for semantic exploration, explicitly encouraging the model to explore richer semantic spaces. To formalize this as an RL problem, we propose the following reward function:

$$
R_t = -\lambda_{\mathscr{D}}(\mathscr{D}_t - \mathscr{D}_{\text{target}})^2 + \lambda_{SE} S_{\text{sem}}(t) + \lambda_{\alpha} (1 - |\alpha_t - \alpha_{\text{target}}|),
$$
\n(1)

where:

- $\mathscr{D}$  quantifies the critical discovery balance between structural and semantic entropy.
- $S_{sem}(t)$  explicitly measures the semantic entropy, encouraging semantic exploration.
- $\alpha_t$  is the fraction of surprising edges (semantically distant but structurally connected edges).
- Hyperparameters  $\lambda_D$ ,  $\lambda_{SE}$ , and  $\lambda_{\alpha}$  balance the relative importance of each term.

Unlike traditional supervised learning, reinforcement learning does not rely on explicit labels. Instead, the model generates actions (such as graph expansions) guided by a learned probability distribution (policy). The gradients flow through this policy, adjusting the parameters to increase the likelihood of actions that yield higher rewards. Formally, the gradient objective (analogous to the gradient of the loss with respect to all model parameters) is:

$$
\nabla_{\theta} J(\theta) = \mathbb{E}_{a \sim \pi_{\theta}(a|G)} \left[ R_t \cdot \nabla_{\theta} \log \pi_{\theta}(a|G) \right],\tag{2}
$$

where:

- $\bullet$   $\nabla_{\theta}J(\theta)$  is the gradient of the expected cumulative reward  $J(\theta)$  with respect to the model parameters  $\theta$ .
- $\bullet \mathbb{E}$  denotes the expectation, indicating that we average over multiple actions  $a$ , which are sampled according to the current policy distribution.
- *a* represents an action taken by the agent, such as adding a new node or edge in the knowledge graph.
- $R_t$  is the scalar reward associated with action a, explicitly computed from the critical discovery metrics defined earlier. Higher  $R_t$  indicates actions leading to desirable semantic exploration and novelty.
- $\pi_{\theta}(a|G)$  is the policy function parameterized by  $\theta$ , representing the probability of taking action  $a$  given the current graph state  $G$ . In practice, we use the logarithm of this probability ( $log \pi_{\theta}(a|G)$ ) because it simplifies the numerical computation of gradients and ensures better stability during training.

Note that, unlike traditional supervised learning where optimization typically involves minimizing an explicit loss function (such as cross-entropy), reinforcement learning explicitly maximizes an expected reward. Therefore, the gradient defined above naturally appears without a minus sign. However, since standard optimization libraries (e.g., PyTorch) conventionally perform gradient descent (minimizing objectives), practitioners commonly define the reinforcement learning objective with an explicit negative sign as follows:

$$
\mathscr{L}_{\mathrm{RL}}(\theta) = -R_t \cdot \log \pi_\theta(a|G).
$$

This negative sign is introduced purely for computational convenience, converting the reward-maximization problem into an equivalent loss-minimization form, aligning with conventional gradient descent routines. Moreover, the theoretical gradient formulation includes an expectation operator  $\mathbb{E}_{a \sim \pi_{\theta}(a|G)}[\cdot]$  because the gradient represents an average over all possible actions according to the policy distribution. Practically, this expectation is approximated by sampling actions from the policy and averaging their resulting rewards.

We note that in reinforcement learning, the policy does not produce explicit answers like in supervised learning. Instead, at every step, it generates a probability distribution over possible actions (such as choosing to add a particular node or edge to the graph). The term  $\log \pi_{\theta}(a|G)$ , known as the *log proba*bility, represents how confident the model was about choosing

a specific action  $a$ . A high log probability indicates high confidence, while a low log probability indicates uncertainty. During training, actions leading to higher rewards are encouraged by increasing their log probabilities, making these beneficial actions more likely in future predictions. Conversely, actions resulting in low or negative rewards have their log probabilities decreased, reducing their likelihood in future decisions. Thus, gradients flow through these log probabilities, guiding the model towards actions that consistently yield higher rewards and better discovery outcomes.

Intuitively, this equation shows how the gradients "flow" during reinforcement learning: the reward  $R_t$  serves as a weighting factor, determining how strongly each action influences parameter updates. Actions yielding higher rewards receive greater weight, making similar actions more probable in future iterations. Conversely, actions resulting in lower or negative rewards reduce their likelihood, guiding the model towards continuous semantic discovery and optimal critical dynamics.

Actions receiving higher rewards become more probable in future iterations, thus shaping the model's semantic discovery behavior.

## III. CONCLUSIONS

This research identifies entropy-based principles governing structural-semantic relationships in artificial reasoning systems. By analyzing entropy dynamics within agentic graph reasoning systems, we uncover insights into the intrinsic nature of continuous discovery and critical phenomena that characterize evolving complex systems. In our experiment, the persistent presence (12%) of structurally connected yet semantically distant ("surprising") edges reveals continuous discovery and adaptive flexibility as emergent properties intrinsic to agentic reasoning models, bridging artificial intelligence, statistical physics, and complex adaptive systems theory. This result confirms the system's ongoing ability to form structurally significant but conceptually "far" connections, thereby operationalizing the idea of semantic "dominance" in a measurable way.

The agentic graph reasoning behaves as a self-organizing critical system, with a critical point as an attractor of its dynamics. The agentic graph reasoning model spontaneously evolves into a critical state, analogous to a high-temperature thermodynamic phase where semantic entropy (favoring disorder) persistently dominates structural organization (favoring order), resulting in a stable, mildly negative critical discovery parameter  $\mathscr{D}$  reminiscent of a free-energy minimum shifted toward disorder<sup>7</sup>, providing evidence that the graph reasoning system is a novel realization of self-organized criticality in an AI context. The structural-semantic transition around iteration 400 (see, Fig.  $4(c)$ ) further underscores the presence of a phase transition-like behavior, consistent with phenomena characteristic of self-organized critical systems. The observed positive correlation between node betweenness centrality and local semantic neighbor diversity indicates that structurally important nodes tend to connect neighborhoods composed of semantically diverse concepts (Fig. 6(c)). Initially, the correlation is strongly positive, reflecting an early phase during which central nodes rapidly integrate semantically distinct clusters. As the network evolves, this correlation steadily decreases and stabilizes at a persistently mild positive value ( $\sim$  0.15) around iteration 400, coinciding with the previously identified critical transition. This subtle yet stable positive correlation demonstrates a sustained structural-semantic configuration in which structurally central nodes serve consistently as local semantic bridges, continuously supporting diverse semantic interactions within their immediate neighborhoods. This structural-semantic balance is consistent with the behaviors characteristic of self-organized critical systems. It suggests that the model is still discovering new relationships and further expands novel insights.

Our analysis demonstrates a subtle but consistent semantic entropy dominance, indicating that while structural evolution occurs algorithmically without direct semantic input, it inherently explores a richer semantic landscape implicitly available in the embedding space. This structural-semantic interplay closely parallels critical behaviors observed in natural systems, such as biological networks and phase transitions in physical materials. In particular, the identified critical structural-semantic transition around iteration 400, where entropy cross-correlation shifts from positive to negative, explicitly mirrors physical phase-transition behavior. Initially, structural and semantic entropies evolve synchronously; beyond this critical point, their dynamics diverge, reflecting a deeper intrinsic mechanism by which systems balance structural coherence with semantic novelty. The stable fraction of surprising edges further elucidates an essential principle: sustained innovation and discovery arise not merely from reinforcing existing structural connections, but crucially through continuously introducing structurally coherent yet semantically novel relationships. This persistent semantic novelty explicitly acts as a reservoir of creative potential, enabling systems to balance structural stability with semantic adaptability and maintain an inherently exploratory, innovative reasoning process.

Ultimately, these findings suggest the existence of universal organizing principles governing both artificial and natural complex adaptive systems. By establishing deep interdisciplinary connections, our results highlight how agentic reasoning architectures, exemplified by the Graph-PRefLexOR model, naturally embody critical phenomena—including subtle semantic-structural interplay, spontaneous structural organization, critical transitions, and sustained exploratory capacity. These insights provide promising foundations for designing next-generation intelligent systems, inspiring interdisciplinary approaches where physics-inspired principles enhance computational creativity, adaptability, and discovery across diverse fields.

The observation that agentic graph reasoning spontaneously evolves towards a critical state exhibiting semantic entropy dominance mirrors the critical localization transitions originally characterized by Aubry in nonlinear and quasiperiodic systems<sup>5,6</sup>. Thus, the principles of subtle structuralsemantic balance identified here generalize Aubry's seminal insights on critical phenomena into the context of adaptive artificial reasoning systems.

Our central finding reveals that continuous innovation in agentic reasoning systems arises fundamentally from entropy dynamics, specifically a subtle yet persistent dominance of semantic entropy over structural entropy. Structural evolution, measured via Von Neumann entropy, implicitly explores a richer semantic landscape characterized by higher semantic entropy, sustaining structurally coherent yet semantically novel ("surprising") relationships. This entropy-driven interplay identifies semantic richness as the intrinsic driver of continuous discovery and adaptability, highlighting a universal entropy-based principle underlying complex adaptive behavior in both artificial and natural systems.

In other words, the reason artificial reasoning systems remain continuously creative and innovative may be because they constantly explore a very rich, diverse, and somewhat chaotic space of possible meanings (this is what we call high semantic entropy). In contrast, the actual connections the system forms, its explicit reasoning structure, are more ordered and constrained (low structural entropy). Because the system always has more meaningful ideas available to explore than it explicitly incorporates into its structure, it can continuously discover and create unexpected, novel relationships. This ongoing imbalance between rich semantic possibilities and more structured connections is what fuels sustained creativity and innovation.

Finally, these insights allowed us to propose a new RL framework that uses key insights developed from the experiments conducted in this paper to further tune AI models to become more creative. For such a system to work, the graphnative reasoning model is a naturally fitting framework as it naturally constructs a structured representation that simultaneously captures semantic diversity and relational structure. For this to work with regular text output, we would need to extract or impose a similar graph or latent network representation to calculate these entropy measures.

## IV. METHODS

The graphs were generated using the graph-native reasoning algorithm described in $^{14}$ , where we let the AI model reason over up to 1,000 iterations. The final graph size has 3,835 nodes and 11,910 edges. The evolution of agent-generated graphs was analyzed using graph-theoretical and semantic embedding metrics. Structural entropy was computed using Von Neumann entropy derived from the normalized Laplacian of the graph. Semantic entropy was calculated based on cosine similarities of node embeddings.

#### A. Node embeddings

Node embeddings were obtained model from a pretrained language (sentence-transformers/all-MiniLM-L6-v2). **PCA** was applied to node embeddings for visualization, revealing structural-semantic relationships and their decoupling.

The critical transition in structural-semantic dynamics was characterized by cross-correlation analysis of structural and semantic entropy time series.

## **B.** Entropy Calculation

We analyzed the structural and semantic evolution of knowledge graphs generated by the Graph-PRefLexOR model, which recursively expands conceptual structures over iterative reasoning cycles.

Structural entropy was quantified using the Von Neumann graph entropy<sup>10,21</sup>, defined explicitly as:

$$
S_{\text{struct}} = -\sum_{i} \lambda_i \log \lambda_i, \tag{3}
$$

where eigenvalues  $\lambda_i$  are computed from the normalized graph Laplacian:

$$
L = I - D^{-1/2} A D^{-1/2}, \tag{4}
$$

where  $A$  is the adjacency matrix,  $D$  is the degree matrix, and I is the identity matrix. To explicitly ensure rigor and comparability, eigenvalues  $\lambda_i$  were normalized to sum to unity prior to entropy calculation, precisely matching our computational implementation.

Semantic entropy was computed analogously. Node labels were first embedded into a semantic vector space using a pretrained neural language model<sup>25</sup> (sentence-transformers/all-MiniLM-L6-v2). A semantic adjacency matrix  $A^{sem}$  was explicitly computed via cosine similarity between node embeddings  $x_i$ ,  $x_j$ :

$$
A_{ij}^{\text{(sem)}} = \frac{\mathbf{x}_i \cdot \mathbf{x}_j}{\|\mathbf{x}_i\| \|\mathbf{x}_j\|},\tag{5}
$$

explicitly scaled to the interval [0,1]. Semantic entropy  $S_{\text{sem}}$ was then analogously calculated from the eigenvalues  $\mu_i$  of the normalized Laplacian derived from the semantic adjacency matrix:

$$
S_{\rm sem} = -\sum_{i} \mu_i \log \mu_i, \tag{6}
$$

where eigenvalues  $\mu_i$  were explicitly normalized to sum to unity. No thresholding was applied to the semantic adjacency matrix, explicitly preserving the complete semantic relationships inherent in the data, thereby ensuring consistency and rigorous comparability with structural entropy measures.

The correlation between structural and semantic entropies across iterations was characterized by cross-correlation analysis, identifying regime shifts in structural-semantic dynamics.

## C. Community detection

Louvain community detection<sup>9</sup> was used to identify structural communities. PCA projections of embeddings revealed semantic relationships relative to structural communities. The Euclidean distance of each node from the centroid of its respective community in PCA space was computed. Community centroids were determined as the mean position of all nodes belonging to a given community. The resulting distribution of node distances was visualized using a histogram, where bin colors represent relative node density, with red indicating higher counts and blue indicating lower values.

### D. Edge detection and classification

Surprising edges are defined as structurally present yet semantically distant (cosine similarity  $\lambda < 0.1$ ). These were quantified to measure sustained semantic novelty.

For completeness, we explicitly analyzed semantic entropy sensitivity across semantic similarity thresholds, observing negligible differences at low thresholds ( $\lambda \leq 0.2$ ), thus confirming robustness.

#### E. Correlation between node betweenness centrality and local semantic diversity

We use the standard definition of betweenness centrality:

$$
\mathrm{BC}(u) = \sum_{s,t} \frac{\sigma_{st}(u)}{\sigma_{st}},
$$

where  $\sigma_{st}(u)$  is the number of shortest paths from s to t that pass through u, and  $\sigma_{st}$  is the total number of shortest paths from  $s$  to  $t$ .

For each node u, let  $N(u)$  be its set of neighbors, and let  $x_i$ denote the embedding vector of neighbor *i*. The local neighbor diversity is the average pairwise Euclidean distance among neighbors:

Diversity
$$
(u)
$$
 =  $\frac{1}{\binom{k}{2}} \sum_{i < j} ||\mathbf{x}_i - \mathbf{x}_j||_2$ ,

and  $k = |N(u)|$  is the node degree of u. If  $k < 2$ , we set Diversity( $u$ ) = 0. We compute Pearson's correlation coefficient between  $BC(u)$  and Diversity $(u)$  across all nodes to assess how bridging roles relate to semantic diversity in the local neighborhood.

## **CONFLICT OF INTEREST**

The author declares no conflict of interest.

## **AUTHOR CONTRIBUTIONS**

MJB designed the research, carried out the research, and wrote the paper.

## **ACKNOWLEDGMENTS**

We wish to acknowledge the support from MIT's Generative AI Initiative.

### **DATA AVAILABILITY STATEMENT**

Codes, model weights and additional materials are available at https://huggingface.co/lamm-mit and https://github.com/lamm-mit/PRefLexOR. The model used for the experiments is available at lamm-mit/ Graph-Preflexor\_01062025.

## **REFERENCES**

<sup>1</sup>Abdin, M., Aneja, J., Awadalla, H., Awadallah, A., Awan, A. A., Bach, N., Bahree, A., Bakhtiari, A., Bao, J., Behl, H., Benhaim, A., Bilenko, M., Bjorck, J., Bubeck, S., Cai, M., Cai, Q., Chaudhary, V., Chen, D., Chen, D., Chen, W., Chen, Y.-C., Chen, Y.-L., Cheng, H., Chopra, P., Dai, X., Dixon, M., Eldan, R., Fragoso, V., Gao, J., Gao, M., Gao, M., Garg, A., Giorno, A. D., Goswami, A., Gunasekar, S., Haider, E., Hao, J., Hewett, R. J., Hu, W., Huynh, J., Iter, D., Jacobs, S. A., Javaheripi, M., Jin, X., Karampatziakis, N., Kauffmann, P., Khademi, M., Kim, D., Kim, Y. J., Kurilenko, L., Lee, J. R., Lee, Y. T., Li, Y., Li, Y., Liang, C., Liden, L., Lin, X., Lin, Z., Liu, C., Liu, L., Liu, M., Liu, W., Liu, X., Luo, C., Madan, P., Mahmoudzadeh, A., Majercak, D., Mazzola, M., Mendes, C. C. T., Mitra, A., Modi, H., Nguyen, A., Norick, B., Patra, B., Perez-Becker, D., Portet, T., Pryzant, R., Qin, H., Radmilac, M., Ren, L., de Rosa, G., Rosset, C., Roy, S., Ruwase, O., Saarikivi, O., Saied, A., Salim, A., Santacroce, M., Shah, S., Shang, N., Sharma, H., Shen, Y., Shukla, S., Song, X., Tanaka, M., Tupini, A., Vaddamanu, P., Wang, C., Wang, G., Wang, L., Wang, S., Wang, X., Wang, Y., Ward, R., Wen, W., Witte, P., Wu, H., Wu, X., Wyatt, M., Xiao, B., Xu, C., Xu, J., Xu, W., Xue, J., Yadav, S., Yang, F., Yang, J., Yang, Y., Yang, Z., Yu, D., Yuan, L., Zhang, C., Zhang, C., Zhang, J., Zhang, L. L., Zhang, Y., Zhang, Y., Zhang, Y., and Zhou, X., "Phi-3 technical report: A highly capable language model locally on your phone," (2024), arXiv:2404.14219 [cs.CL].

- <sup>2</sup>Abdin, M., Aneja, J., Behl, H., Bubeck, S., Eldan, R., Gunasekar, S., Harrison, M., Hewett, R. J., Javaheripi, M., Kauffmann, P., Lee, J. R., Lee, Y. T., Li, Y., Liu, W., Mendes, C. C. T., Nguyen, A., Price, E., de Rosa, G., Saarikivi, O., Salim, A., Shah, S., Wang, X., Ward, R., Wu, Y., Yu, D., Zhang, C., and Zhang, Y., "Phi-4 technical report," (2024), arXiv:2412.08905 [cs.CL].
- <sup>3</sup>Alec Radford,, Karthik Narasimhan,, Tim Salimans,, and Ilya Sutskever,, .
- <sup>4</sup>AlQuraishi, M., Cell Systems 0 (2019), 10.1016/j.cels.2019.03.006.
- <sup>5</sup>Aubry, S., Physica D: Nonlinear Phenomena 103, 201 (1997).
- $6$ Aubry, S. and André, G., Annals of the Israel Physical Society 3, 18 (1980). <sup>7</sup>Bak, P., Tang, C., and Wiesenfeld, K., Physical Review Letters 59, 381  $(1987).$
- <sup>8</sup>Barabási, A.-L. and Albert, R., Science 286, 509 (1999).
- <sup>9</sup>Blondel, V. D., Guillaume, J.-L., Lambiotte, R., and Lefebvre, E., Journal of Statistical Mechanics: Theory and Experiment 2008, P10008 (2008).
- <sup>10</sup>Braunstein, S. L., Ghosh, S., and Severini, S., Annals of Combinatorics 10, 291 (2006).
- <sup>11</sup> Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D., (2020).
- <sup>12</sup>Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., et al., Advances in Neural Information Processing Systems 33, 1877 (2020).
- <sup>13</sup>Buehler, M. J., npj Artififical Intelligence (2024), arXiv:2410.12375 [cs.AI].

- <sup>15</sup>Buehler, M. J., "Graph-aware isomorphic attention for adaptive dynamics in transformers," (2025), arXiv:2501.02393 [cs.LG].
- <sup>16</sup>Buehler, M. J., "In-situ graph reasoning and knowledge expansion using Graph-pRefLexOR," (2025), arXiv:2501.08120 [cs.AI].
- <sup>17</sup> Carnap, R. and Bar-Hillel, Y., Technical report (Massachusetts Institute of Technology. Research Laboratory of Electronics) (1952).
- <sup>18</sup>Giesa, T., Spivak, D., and Buehler, M., BioNanoScience 1 (2011), 10.1007/s12668-011-0022-5.
- <sup>19</sup>Giesa, T., Spivak, D., and Buehler, M., Advanced Engineering Materials 14 (2012), 10.1002/adem.201200109.
- <sup>20</sup>Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A., Vaughan, A., Yang, A., Fan, A., Goyal, A., Hartshorn, A., Yang, A., Mitra, A., Sravankumar, A., Korenev, A., Hinsvark, A., Rao, A., Zhang, A., Rodriguez, A., Gregerson, A., Spataru, A., Roziere, B., Biron, B., Tang, B., Chern, B., Caucheteux, C., Nayak, C., Bi, C., Marra, C., McConnell, C., Keller, C., Touret, C., Wu, C., Wong, C., Ferrer, C. C., Nikolaidis, C., Allonsius, D., Song, D., Pintz, D., Livshits, D., Wyatt, D., Esiobu, D., Choudhary, D., Mahajan, D., Garcia-Olano, D., Perino, D., Hupkes, D., Lakomkin, E., AlBadawy, E., Lobanova, E., Dinan, E., Smith, E. M., Radenovic, F., Guzmán, F., Zhang, F., Synnaeve, G., Lee, G., Anderson, G. L., Thattai, G., Nail, G., Mialon, G., Pang, G., Cucurell, G., Nguyen, H., Korevaar, H., Xu, H., Touvron, H., Zarov, I., Ibarra, I. A., Kloumann, I., Misra, I., Evtimov, I., Zhang, J., Copet, J., Lee, J., Geffert, J., Vranes, J., Park, J., Mahadeokar, J., Shah, J., van der Linde, J., Billock, J., Hong, J., Lee, J., Fu, J., Chi, J., Huang, J., Liu, J., Wang, J., Yu, J., Bitton, J., Spisak, J., Park, J., Rocca, J., Johnstun, J., Saxe, J., Jia, J., Alwala, K. V., Prasad, K., Upasani, K., Plawiak, K., Li, K., Heafield, K., Stone, K., El-Arini, K., Iyer, K., Malik, K., Chiu, K., Bhalla, K., Lakhotia, K., Rantala-Yeary, L., van der Maaten, L., Chen, L., Tan, L., Jenkins, L., Martin, L., Madaan, L., Malo, L., Blecher, L., Landzaat, L., de Oliveira, L., Muzzi, M., Pasupuleti, M., Singh, M., Paluri, M., Kardas, M., Tsimpoukelli, M., Oldham, M., Rita, M., Pavlova, M., Kambadur, M., Lewis, M., Si, M., Singh, M. K., Hassan, M., Goyal, N., Torabi, N., Bashlykov, N., Bogoychev, N., Chatterji, N., Zhang, N., Duchenne, O., Çelebi, O., Alrassy, P., Zhang, P., Li, P., Vasic, P., Weng, P., Bhargava, P., Dubal, P., Krishnan, P., Koura, P. S., Xu, P., He, Q., Dong, Q., Srinivasan, R., Ganapathy, R., Calderer, R., Cabral, R. S., Stojnic, R., Raileanu, R., Maheswari, R., Girdhar, R., Patel, R., Sauvestre, R., Polidoro, R., Sumbaly, R., Taylor, R., Silva, R., Hou, R., Wang, R., Hosseini, S., Chennabasappa, S., Singh, S., Bell, S., Kim, S. S., Edunov, S., Nie, S., Narang, S., Raparthy, S., Shen, S., Wan, S., Bhosale, S., Zhang, S., Vandenhende, S., Batra, S., Whitman, S., Sootla, S., Collot, S., Gururangan, S., Borodinsky, S., Herman, T., Fowler, T., Sheasha, T., Georgiou, T., Scialom, T., Speckbacher, T., Mihaylov, T., Xiao, T., Karn, U., Goswami, V., Gupta, V., Ramanathan, V., Kerkez, V., Gonguet, V., Do, V., Vogeti, V., Albiero, V., Petrovic, V., Chu, W., Xiong, W., Fu, W., Meers, W., Martinet, X., Wang, X., Wang, X., Tan, X. E., Xia, X., Xie, X., Jia, X., Wang, X., Goldschlag, Y., Gaur, Y., Babaei, Y., Wen, Y., Song, Y., Zhang, Y., Li, Y., Mao, Y., Coudert, Z. D., Yan, Z., Chen, Z., Papakipos, Z., Singh, A., Srivastava, A., Jain, A., Kelsey, A., Shajnfeld, A., Gangidi, A., Victoria, A., Goldstand, A., Menon, A., Sharma, A., Boesenberg, A., Baevski, A., Feinstein, A., Kallet, A., Sangani, A., Teo, A., Yunus, A., Lupu, A., Alvarado, A., Caples, A., Gu, A., Ho, A., Poulton, A., Ryan, A., Ramchandani, A., Dong, A., Franco, A., Goyal, A., Saraf, A., Chowdhury, A., Gabriel, A., Bharambe, A., Eisenman, A., Yazdan, A., James, B., Maurer, B., Leonhardi, B., Huang, B., Loyd, B., Paola, B. D., Paranjape, B., Liu, B., Wu, B., Ni, B., Hancock, B., Wasti, B., Spence, B., Stojkovic, B., Gamido, B., Montalvo, B., Parker, C., Burton, C., Mejia, C., Liu, C., Wang, C., Kim, C., Zhou, C., Hu, C., Chu, C.-H., Cai, C., Tindal, C., Feichtenhofer, C., Gao, C., Civin, D., Beaty, D., Kreymer, D., Li, D., Adkins, D., Xu, D., Testuggine, D., David, D., Parikh, D., Liskovich, D., Foss, D., Wang, D., Le, D., Holland, D., Dowling, E., Jamil, E., Montgomery, E., Presani, E., Hahn, E., Wood, E., Le, E.-T., Brinkman, E., Arcaute, E., Dunbar, E., Smothers, E., Sun, F., Kreuk, F., Tian, F., Kokkinos, F., Ozgenel,

- F., Caggioni, F., Kanayet, F., Seide, F., Florez, G. M., Schwarz, G., Badeer, G., Swee, G., Halpern, G., Herman, G., Sizov, G., Guangyi,, Zhang,, Lakshminarayanan, G., Inan, H., Shojanazeri, H., Zou, H., Wang, H., Zha, H., Habeeb, H., Rudolph, H., Suk, H., Aspegren, H., Goldman, H., Zhan, H., Damlaj, I., Molybog, I., Tufanov, I., Leontiadis, I., Veliche, I.-E., Gat, I., Weissman, J., Geboski, J., Kohli, J., Lam, J., Asher, J., Gaya, J.-B., Marcus, J., Tang, J., Chan, J., Zhen, J., Reizenstein, J., Teboul, J., Zhong, J., Jin, J., Yang, J., Cummings, J., Carvill, J., Shepard, J., McPhie, J., Torres, J., Ginsburg, J., Wang, J., Wu, K., U, K. H., Saxena, K., Khandelwal, K., Zand, K., Matosich, K., Veeraraghavan, K., Michelena, K., Li, K., Jagadeesh, K., Huang, K., Chawla, K., Huang, K., Chen, L., Garg, L., A, L., Silva, L., Bell, L., Zhang, L., Guo, L., Yu, L., Moshkovich, L., Wehrstedt, L., Khabsa, M., Avalani, M., Bhatt, M., Mankus, M., Hasson, M., Lennie, M., Reso, M., Groshev, M., Naumov, M., Lathi, M., Keneally, M., Liu, M., Seltzer, M. L., Valko, M., Restrepo, M., Patel, M., Vyatskov, M., Samvelyan, M., Clark, M., Macey, M., Wang, M., Hermoso, M. J., Metanat, M., Rastegari, M., Bansal, M., Santhanam, N., Parks, N., White, N., Bawa, N., Singhal, N., Egebo, N., Usunier, N., Mehta, N., Laptev, N. P., Dong, N., Cheng, N., Chernoguz, O., Hart, O., Salpekar, O., Kalinli, O., Kent, P., Parekh, P., Saab, P., Balaji, P., Rittner, P., Bontrager, P., Roux, P., Dollar, P., Zvyagina, P., Ratanchandani, P., Yuvraj, P., Liang, Q., Alao, R., Rodriguez, R., Ayub, R., Murthy, R., Nayani, R., Mitra, R., Parthasarathy, R., Li, R., Hogan, R., Battey, R., Wang, R., Howes, R., Rinott, R., Mehta, S., Siby, S., Bondu, S. J., Datta, S., Chugh, S., Hunt, S., Dhillon, S., Sidorov, S., Pan, S., Mahajan, S., Verma, S., Yamamoto, S., Ramaswamy, S., Lindsay, S., Lindsay, S., Feng, S., Lin, S., Zha, S. C., Patil, S., Shankar, S., Zhang, S., Zhang, S., Wang, S., Agarwal, S., Sajuyigbe, S., Chintala, S., Max, S., Chen, S., Kehoe, S., Satterfield, S., Govindaprasad, S., Gupta, S., Deng, S., Cho, S., Virk, S., Subramanian, S., Choudhury, S., Goldman, S., Remez, T., Glaser, T., Best, T., Koehler, T., Robinson, T., Li, T., Zhang, T., Matthews, T., Chou, T., Shaked, T., Vontimitta, V., Ajayi, V., Montanez, V., Mohan, V., Kumar, V. S., Mangla, V., Ionescu, V., Poenaru, V., Mihailescu, V. T., Ivanov, V., Li, W., Wang, W., Jiang, W., Bouaziz, W., Constable, W., Tang, X., Wu, X., Wang, X., Wu, X., Gao, X., Kleinman, Y., Chen, Y., Hu, Y., Jia, Y., Qi, Y., Li, Y., Zhang, Y., Zhang, Y., Adi, Y., Nam, Y., Yu,, Wang,, Zhao, Y., Hao, Y., Qian, Y., Li, Y., He, Y., Rait, Z., DeVito, Z., Rosnbrick, Z., Wen, Z., Yang, Z., Zhao, Z., and Ma, Z., "The Ilama 3 herd of models," (2024), arXiv:2407.21783 [cs.AI].
- $^{21}$ Kauffman, S. A., The Origins of Order: Self-Organization and Selection in Evolution (Oxford University Press, 1993).
- $^{22}$ Latora, V. and Marchiori, M., Phys. Rev. Lett. 87, 198701 (2001).
- <sup>23</sup>Li, Y., Bubeck, S., Eldan, R., Giorno, A. D., Gunasekar, S., and Lee, Y. T., "Textbooks are all you need ii: phi-1.5 technical report," (2023), arXiv:2309.05463 [cs.CL].
- $^{24}$ Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013) arXiv:1301.3781  $[cs. CL]$ .
- <sup>25</sup>Reimers, N. and Gurevych, I., Proceedings of EMNLP-IJCNLP, 3982  $(2019).$
- <sup>26</sup>Salinas, H., Brahm, R., Olmschenk, G., Barry, R. K., Pichara, K., Silva, S. I., and Araujo, V., "Exoplanet transit candidate identification in tess full-frame images via a transformer-based algorithm," (2025), arXiv:2502.07542 [astro-ph.EP].
- <sup>27</sup>Solé, R. V. and Valverde, S., Lecture Notes in Physics  $650$ , 189 (2004).
- <sup>28</sup>Spivak, D., Giesa, T., Wood, E., and Buehler, M., PLoS ONE 6 (2011), 10.1371/journal.pone.0023911.
- <sup>29</sup>Stanley, H. E., *Introduction to Phase Transitions and Critical Phenomena* (Oxford University Press, Oxford, 1987).
- <sup>30</sup>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I., in Advances in Neural Information Processing Systems, Vol. 2017-December (Neural information processing systems foundation, 2017) pp. 5999-6009.
- <sup>31</sup> Watts, D. J. and Strogatz, S. H., Nature 393, 440 (1998).
- <sup>32</sup> Yao, S., Pennington, J., et al., "Tree of thoughts: Deliberate problem solving with large language models," (2023).
- <sup>33</sup>Zelikman, E., Wu, Y., Mu, J., and Goodman, N. D., "Star: Bootstrapping reasoning with reasoning," (2022), arXiv:2203.14465 [cs.LG].